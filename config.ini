# ==============================================================================
# Main Configuration for the LLM Narrative Framework
# ==============================================================================
# This file controls all parameters for the experimental pipeline, from
# data paths to model settings and analysis configurations.

[Study]
# Study-level experimental design parameters. Used by new_experiment.ps1 to 
# present interactive selection of experimental conditions. Multiple values 
# are comma-separated. Single values are used without prompting. Leave empty 
# to use [Experiment]/[LLM] defaults directly.
mapping_strategy = correct, random
group_size = 7, 10, 14
num_replications = 30
num_trials = 80
model_name = anthropic/claude-sonnet-4, google/gemini-2.0-flash-lite-001, meta-llama/llama-3.3-70b-instruct, openai/gpt-4o, deepseek/deepseek-chat-v3.1, qwen/qwen-2.5-72b-instruct, mistralai/mistral-large-2411
temperature = 0.0
max_tokens = 1024

[Experiment]
# High-level parameters defining the entire experimental design.
# Number of replications to execute (r)
num_replications = 30
# Number of trials for each replication (m)
num_trials = 80
# Number of subjects in each group (k)                              [Set by interactive Study parameter]
group_size = 7
# The ground truth mapping to use. Options: 'correct', 'random'.    [Set by interactive Study parameter]
mapping_strategy = random

[LLM]
# Parameters specific to the Language Model's behavior.
model_name = google/gemini-2.0-flash-lite-001
temperature = 0.0
max_tokens = 1024
# The maximum number of concurrent API calls to make during a replication run.
# A higher number can significantly speed up the experiment but may hit API rate limits.
# Recommended value: 10
max_parallel_sessions = 10

[API]
# Global settings for the API provider.
api_endpoint = https://openrouter.ai/api/v1/chat/completions
referer_header = http://localhost:3000
api_timeout_seconds = 120

[General]
# Housekeeping settings for file and directory names.
# Base directory for all pipeline outputs
base_output_dir = output
# Subdirectory for query files generated by build_queries.py
queries_subdir = session_queries
# Subdirectory for LLM responses generated by conduct_llm_sessions.py
responses_subdir = session_responses
# Subdirectory for processed scores and mappings ready for meta-analysis
analysis_inputs_subdir = analysis_inputs
# Subdirectory under 'output' for run reports
reports_subdir = reports
# Subdirectory within 'base_output_dir' for new, timestamped experiments
new_experiments_subdir = new_experiments
# Prefix for timestamped experiment directories
experiment_dir_prefix = experiment_
# Top-level directory for run archives
archives_dir = archives
# Global verbosity level (INFO, DEBUG, WARNING, ERROR, CRITICAL) for logging
# Scripts can have their own --verbose flags to override this for a single run
default_log_level = INFO

[Filenames]
# Source files (relative to the script needing them, or resolved to be alongside scripts)
personalities_src = personalities_db.txt
base_query_src = base_query.txt
successful_indices_log = successful_query_indices.txt

# Tracking and aggregated files (names within their respective subdirectories)
used_indices_log = used_personality_indices.txt
aggregated_mappings_in_queries_dir = mappings.txt 

# Final files for meta-analysis script
all_scores_for_analysis = all_scores.txt
all_mappings_for_analysis = all_mappings.txt

# Temporary file used by build_queries.py and query_generator.py
temp_subset_personalities = temp_personalities_subset.txt
# Prefix for temporary files is created by query_generator.py
# qgen_temp_prefix

[MetaAnalysis]
# Default Top-K for accuracy in run_meta_analysis.py
default_top_k_accuracy = 3
# Delimiter expected by run_meta_analysis.py for its input files.
# 'None' means whitespace, or specify like ',' or '\t'.
# If process_responses.py outputs tab-delimited, this should be '\t'.
analysis_input_delimiter = \t 

[Schema]
# Defines the standard column names used across the analysis pipeline.

# Columns that define the experimental conditions (independent variables).
factors = model, mapping_strategy, temperature, k, m

# Columns that contain the performance results to be analyzed (dependent variables).
metrics = mean_mrr,mean_top_1_acc,mean_top_3_acc,mean_mrr_lift,mean_top_1_acc_lift,mean_top_3_acc_lift,mean_rank_of_correct_id,n_valid_responses,top1_pred_bias_std,true_false_score_diff,bias_slope,bias_p_value

# The full, ordered list of columns for the final CSV output.
# This ensures every generated summary file has a consistent layout.
csv_header_order = run_directory,replication,n_valid_responses,model,mapping_strategy,temperature,k,m,db,mean_mrr,mrr_p,mean_top_1_acc,top_1_acc_p,mean_top_3_acc,top_3_acc_p,mean_mrr_lift,mean_top_1_acc_lift,mean_top_3_acc_lift,mean_rank_of_correct_id,rank_of_correct_id_p,top1_pred_bias_std,true_false_score_diff,bias_slope,bias_intercept,bias_r_value,bias_p_value,bias_std_err

[ModelNormalization]
# Maps raw keywords found in run directories to a single, canonical internal name.
# This version systematically includes both hyphenated and underscored variants for maximum robustness.
# format: canonical_name = comma,separated,keyword(s)
deepseek-v3                      = deepseek-chat-v3, deepseek_chat_v3
google-gemini-2-0-flash          = gemini-2.0-flash, gemini_2_0_flash
google-gemini-2-5-flash          = gemini-2.5-flash, gemini_2_5_flash
google-gemini-flash-1-5          = gemini-flash-1.5, gemini_flash_1_5
google-gemma-3-27b               = gemma-3-27b, gemma_3_27b
meta-llama-3-3-70b               = llama-3.3-70b, llama_3_3_70b
meta-llama-4-maverick            = llama-4-maverick, llama_4_maverick
mistralai-mistral-medium-3       = mistral-medium-3, mistral_medium_3
mistralai-mistral-small-3-1      = mistral-small-3.1, mistral_small_3_1
nvidia-llama-3-1-nemotron-ultra  = nemotron-ultra
openai-gpt-4-1-mini              = gpt-4.1-mini, gpt_4.1_mini
openai-gpt-4o-mini               = gpt-4o-mini, gpt_4o_mini
qwen-qwen3-235b                  = qwen3-235b, qwen_235b
xai-grok-3-mini-beta             = grok-3-mini-beta, grok_3_mini_beta

[ModelDisplayNames]
# Maps the canonical internal names to human-readable names for plots and reports.
# The keys here MUST exactly match the keys in the [ModelNormalization] section.
# format: canonical_name = Friendly Display Name
deepseek-v3                                 = DeepSeek V3
claude-sonnet-4                             = Claude Sonnet 4
claude-sonnet-4-5                           = Claude Sonnet 4.5
deepseek-deepseek-chat-v3-0324              = DeepSeek V3 0324
gemini-2-5-pro                              = Gemini 2.5 Pro
google-gemini-2-0-flash-lite-001            = Gemini 2.0 Flash Lite
google-gemini-2-5-flash-lite                = Gemini 2.5 Flash Lite
google-gemini-2-5-flash-lite-preview-06-17  = Gemini 2.5 Flash Lite Preview 06-17
google-gemini-2-0-flash                     = Gemini 2.0 Flash
google-gemini-2-5-flash                     = Gemini 2.5 Flash
google-gemini-flash-1-5                     = Gemini 1.5 Flash
google-gemma-3-27b                          = Gemma 3 27B
gpt-5-chat                                  = GPT 5 Chat
meta-llama-3-3-70b                          = Llama 3.3 70B
meta-llama-4-maverick                       = Llama 4 Maverick
meta-llama-llama-3-3-70b-instruct           = Llama 3.3 70B Instruct
meta-llama-llama-4-maverick                 = Llama 4 Maverick
mistralai-mistral-medium-3                  = Mistral Medium 3
mistralai-mistral-small-3-2-24b-instruct    = Mistral Small 3.2 24B
mistralai-mistral-small-3-1                 = Mistral Small 3.1
nvidia-llama-3-1-nemotron-ultra             = Llama 3.1 Nemotron Ultra 253B
openai-gpt-4-1-nano                         = GPT 4.1 Nano
openai-gpt-4-1-mini                         = GPT 4.1 mini
openai-gpt-4o-mini                          = GPT 4o mini
qwen-qwen3-235b                             = Qwen3 235B
qwen-qwen3-coder                            = Qwen3 Coder 480B A35B
xai-grok-3-mini-beta                        = Grok 3 Mini

[ConfigCompatibility]
# This section provides a fallback map for legacy configuration files.
# The format is: canonical_name = new_section:new_key, old_section:old_key
# Scripts will try these locations in order, with the most modern format listed first.

model_name = LLM:model_name, Model:model_name, LLM:model
num_trials = Experiment:num_trials, Study:num_trials, Study:num_iterations
num_subjects = Experiment:group_size, Experiment:group_size, Study:group_size, Study:num_subjects, Study:k_per_query
mapping_strategy = Experiment:mapping_strategy, Study:mapping_strategy
personalities_db_path = Filenames:personalities_src, General:personalities_db_path

[FactorDisplayNames]
# Maps internal factor names to human-readable names for plots and reports.
model = Model
mapping_strategy = Mapping Strategy
temperature = Temperature
k = Group Size (k)
m = Number of Trials (m)

[MetricDisplayNames]
# Maps internal metric names to human-readable names for plots and reports.
mean_mrr = Mean Reciprocal Rank (MRR)
mean_top_1_acc = Top-1 Accuracy
mean_top_3_acc = Top-3 Accuracy
mean_mrr_lift = MRR Lift (vs. Chance)
mean_top_1_acc_lift = Top-1 Accuracy Lift (vs. Chance)
mean_top_3_acc_lift = Top-3 Accuracy Lift (vs. Chance)
mean_rank_of_correct_id = Mean Rank of Correct ID
n_valid_responses = Valid Responses
top1_pred_bias_std = Top-1 Prediction Bias (Std Dev)
true_false_score_diff = True vs. False Score Difference
bias_slope = Bias Slope
bias_p_value = Bias P-value

[Analysis]
# The minimum average number of valid responses per replication for a model to be
# included in the final statistical analysis. Models below this are excluded.
# Set to 0 to disable filtering. A value of 25 is a reasonable default to
# exclude models that failed to produce responses for most trials.
min_valid_response_threshold = 25

[DataGeneration]
# Settings for scripts that generate foundational data assets.

# Methodological Controls
# ---
# Setting this to 'true' will cause the data pipeline to bypass the LLM-based
# candidate selection process (eminence and OCEAN scoring). The pipeline will
# instead use the full list of "eligible" candidates as the final subject pool.
# This provides a control for validating findings without the potential confound
# of an LLM-based selection method.
bypass_candidate_selection = false

# Eminence Score Generation Settings
# ---
# The LLM to use for eminence scoring.
eminence_model = openai/gpt-5-chat
# Number of subjects per API call for eminence scoring.
eminence_batch_size = 100
# Path for the final eminence scores CSV file.
eminence_scores_output = data/foundational_assets/eminence_scores.csv
# Path to the raw, tab-delimited file exported from ADB.
raw_adb_export_input = data/sources/adb_raw_export.txt

# OCEAN Score Generation Settings
# ---
# Path for the final OCEAN scores CSV file.
ocean_scores_output = data/foundational_assets/ocean_scores.csv
# Name of the LLM to use for OCEAN scoring.
ocean_model = anthropic/claude-sonnet-4.5
# Number of subjects per API call for OCEAN scoring.
ocean_batch_size = 50

# Final Candidate Selection Settings
# ---
# The minimum number of subjects required to run the variance analysis.
min_population_size = 100
# The cohort size at which to start searching for the cutoff point. This avoids
# instability in the initial part of the variance curve.
cutoff_search_start_point = 1000
# The slope threshold for detecting the curve's plateau. The cutoff is set where
# the curve's gradient first becomes less negative than this value.
slope_threshold = -0.00001
# The window size for the moving average used to smooth the variance curve.
# A larger window creates a smoother curve, making the global trend clearer.
smoothing_window_size = 1500
# Path for the diagnostic plot of the variance curve analysis.
variance_plot_output = data/foundational_assets/variance_curve_analysis.png

# Delineation Neutralization Settings
# ---
# Name of the LLM to use for neutralizing delineations.
neutralization_model = google/gemini-2.5-pro
# Comma-separated list of points to include in the 'points_in_signs' output.
points_for_neutralization = Sun, Moon, Mercury, Venus, Mars, Jupiter, Saturn, Uranus, Neptune, Pluto, Ascendant, Midheaven

[SolarFire]
# Settings for the Solar Fire software integration
# Base directory for Solar Fire user files (typically in Documents)
user_files_base = Documents\Solar Fire User Files
# Subdirectory for exported chart data
chart_export_subdir = Export
# Filename for the chart export file
chart_export_filename = sf_chart_export.csv
# Subdirectory for interpretation files
delin_lib_subdir = Export
# Filename for the delineation library file
delin_lib_filename = sf_delineations_library.txt
