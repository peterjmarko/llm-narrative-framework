# Data Directory

This document is the **Data Dictionary** for the project. Its purpose is to describe the contents and structure of the `data/` directory, explaining the role of each file in the data preparation and analysis pipelines.

## Directory Structure

```
data/
│
├── README.md                   # This file.
├── base_query.txt              # LLM prompt template for the matching task.
├── personalities_db.txt        # FINAL PRODUCT: The main database used in experiments.
│
├── sources/
│   └── adb_raw_export.txt      # Raw data dump from the automated fetching script.
│
├── reports/
│   ├── adb_validation_report.csv
│   ├── adb_validation_summary.txt
│   ├── missing_eminence_scores.txt
│   └── name_mismatches.csv
│
├── foundational_assets/
│   ├── neutralized_delineations/   # Sanitized text snippets for database assembly.
│   ├── sf_chart_export.csv         # Chart data exported from Solar Fire (manual step).
│   ├── sf_delineations_library.txt # The original, raw delineations exported from Solar Fire.
│   ├── country_codes.csv           # Mapping of ADB country/state codes to full names.
│   ├── eminence_scores.csv         # Static scores used for final subject selection.
│   ├── point_weights.csv           # Configurable weights for planets/points.
│   └── balance_thresholds.csv      # Configurable thresholds for balance calculations.
│
├── intermediate/
│   ├── adb_filtered_5000.txt   # The 5,000 subjects after initial filtering.
│   └── sf_data_import.txt      # Subjects formatted for Solar Fire import.
│
├── processed/
│   └── subject_db.csv          # Cleaned, integrated master database ready for generation.
│
└── backup/
    └── ... (timestamped backups) # Automatic backups of generated files.
```

## File Descriptions by Directory

### 1. `sources/` - Raw Data

This directory contains the original, unprocessed starting point for the pipeline.

-   **`adb_raw_export.txt`**: The raw data dump from Astro-Databank, generated by `fetch_adb_data.py`. For direct replication of the study, use the version of this file included in the repository. For new research, this file is the first to be generated. It includes standardized identifiers (`Index`, `idADB`) and pre-calculated timezone information.

### 2. `reports/` - Validation & Audit Files

These files are generated during the data validation and filtering stages.

-   **`adb_validation_report.csv`**: The detailed, row-by-row output of `validate_adb_data.py`. It is used as a master filter by `filter_adb_candidates.py` to ensure reproducibility.
-   **`adb_validation_summary.txt`**: A human-readable summary of the validation report.
-   **`missing_eminence_scores.txt`**: A log of subjects who were excluded because they lacked an eminence score.
-   **`name_mismatches.csv`**: A log of subjects excluded due to a name mismatch between `adb_raw_export.txt` and `eminence_scores.csv`, indicating a data integrity issue.

### 3. `foundational_assets/` - Static Assets for Generation

These files are static, pre-prepared assets that provide the rules and content for generating the final personality descriptions.

-   **`eminence_scores.csv`**: Contains the LLM-generated eminence score for every subject in the raw export. It is created by `generate_eminence_scores.py` and is used by `filter_adb_candidates.py` to rank and select the final 5,000 subjects. The file is sorted by `EminenceScore` and contains the headers: `Index`, `idADB`, `Name`, `EminenceScore`.
-   **`country_codes.csv`**: A mapping file to resolve country/state abbreviations.
-   **`sf_delineations_library.txt`**: The raw, complete library of interpretive text as exported from Solar Fire.
-   **`neutralized_delineations/`**: A directory containing the sanitized, de-jargonized description components, ready for assembly.
-   **`sf_chart_export.csv`**: The raw data exported from Solar Fire after it has processed the subjects. This is the output of a manual step in the pipeline.
-   **`point_weights.csv` & `balance_thresholds.csv`**: Configuration files that define the core logic for the personality classification algorithm in `generate_personalities_db.py`.

### 4. `intermediate/` - Pipeline Artifacts

These files are the outputs of one pipeline script and the inputs to the next.

-   **`adb_filtered_5000.txt`**: The output of `filter_adb_candidates.py`. It contains the top 5,000 subjects, sorted by eminence. This file serves as a key input for two downstream processes: it provides the subject list for `prepare_sf_import.py` and is used for cross-referencing by `create_subject_db.py`.
-   **`sf_data_import.txt`**: The output of `prepare_sf_import.py`. This file is formatted for direct import into the Solar Fire software.

### 5. `processed/` - Cleaned Master Database

This directory holds the cleaned and integrated master data file, ready for the final generation step.

-   **`subject_db.csv`**: The output of `create_subject_db.py`. This script integrates the Solar Fire chart data with the filtered subject list, fixes character encoding errors, and produces this clean, UTF-8 encoded master CSV with `Index` and `idADB` as the primary identifiers.

### 6. Top-Level Files - Main Experiment Files

These are the final, high-level files used directly in the LLM experiments.

-   **`personalities_db.txt`**: This is the final, primary database used in all experiments. It is generated by `generate_personalities_db.py` and contains the columns `Index`, `idADB`, `Name`, `BirthYear`, and `DescriptionText`.
-   **`base_query.txt`**: A text file containing the prompt template for the LLM matching task.

## Transition to the Main Experiment Pipeline

Once the data preparation pipeline is complete, its primary output, `personalities_db.txt`, serves as the foundational database for the main experiments. This file, together with the `base_query.txt` prompt template, provides the necessary inputs for the first stage of the main experimental workflow.

For a detailed explanation of the subsequent experimental and analysis pipeline, please refer to the project's main **Framework Manual**.