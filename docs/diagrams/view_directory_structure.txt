## Directory Structure

This logical hierarchy is reflected in the physical layout of the repository:

personality_matching/
├── README.md                   # You are here!
├── CONTRIBUTING.md             # Guidelines for contributors
├── pyproject.toml              # Project dependencies and metadata (for PDM)
|
├── .env                        # Stores private API keys (not committed)
├── config.ini                  # Main configuration for running experiments
|
├── analyze_study.ps1           # ENTRY POINT: Analyze a completed study's results
├── audit_experiment.ps1        # ENTRY POINT: Audit an experiment's completeness
├── migrate_experiment.ps1      # ENTRY POINT: Migrate old experiment data
├── new_experiment.ps1          # ENTRY POINT: Create a new experiment from scratch
├── run_experiment.ps1          # ENTRY POINT: Repair or resume an existing experiment
└── update_experiment.ps1       # ENTRY POINT: Re-run analysis for an existing experiment
|
├── src/                        # All Python source code for the project
│   ├── aggregate_experiments.py      # Aggregates experiments into a study summary
│   ├── analyze_llm_performance.py  # Stage 4a: Calculates core metrics
│   ├── build_llm_queries.py        # Stage 1: Generates all trial queries
│   ├── compile_experiment_results.py # Compiles all replications for an experiment
│   ├── compile_replication_results.py# Stage 6: Compiles results for one replication
│   ├── experiment_manager.py       # Main controller for a single experiment
│   ├── generate_replication_report.py# Stage 5: Creates the final text report
│   ├── llm_prompter.py             # Worker: Handles a single API call
│   ├── orchestrate_replication.py  # Orchestrates the 6 stages for one replication
│   ├── process_llm_responses.py    # Stage 3: Parses LLM text responses
│   ├── query_generator.py          # Worker: Generates a single query file
│   ├── replication_log_manager.py  # Manages batch_run_log.csv
│   ├── run_bias_analysis.py        # Stage 4b: Calculates bias metrics
│   ├── run_llm_sessions.py         # Stage 2: Manages parallel LLM API calls
│   └── study_analyzer.py           # Final: Performs statistical analysis for a study
|
├── data/                               # Source personality databases & prompt templates
│   ├── personalities_db_1-5000.txt     # Main personalities database used in experiments
│   └── base_query.txt                  # Template for LLM prompts
|
├── output/                                     # All generated artifacts from experiments
│   ├── new_experiments/                        # Contains all new experiments
│       └── <Experiment_Name>/                          # e.g., "Grok_3_Mini_map=random"
│           ├── <Replication_Name>/                     # e.g., "run_..._rep-01_..._rps-030_mps-random"
│           │   ├── analysis_inputs/                    # Intermediate data for ANOVA consumption
│           │   ├── session_queries/                    # Raw LLM queries (JSON and text)
│           │   ├── session_responses/                  # Raw LLM responses (JSON and text)
│           │   ├── api_times.log                       # Run times of API calls
│           │   ├── config.ini.archived                 # Config snapshot for the run
│           │   ├── replication_report_DATE-TIME.txt    # Detailed report for this run
│           │   └── REPLICATION_results.csv             # AGGREGATE: Summary of all trials within a replication
│           ├── batch_run_log.csv                       # Log of all replication runs in an experiment
│           └── EXPERIMENT_results.csv                  # AGGREGATE: Summary of all replications within an experiment
│   └── studies/                                    # Contains all experiment and study outputs
│       └── <Study_Name>/                           # e.g., "Study_1"
│           ├── anova/                                      # Statistical analysis outputs (if run at this level)
│           │   ├── boxplots/                               # Publication-quality plots
│           │   ├── diagnostics/                            # Q-Q plots for checking statistical assumptions
│           │   └── STUDY_analysis_log.txt                  # Comprehensive text report of statistical findings
│           ├── <Experiment_Name>/                          # e.g., "Grok_3_Mini_map=random"
│           │   ├── <Replication_Name>/                     # e.g., "run_..._rep-01_..."
│           │   │   ├── analysis_inputs/                    # Intermediate data for ANOVA consumption
│           │   │   ├── session_queries/                    # Raw LLM queries (JSON and text)
│           │   │   ├── session_responses/                  # Raw LLM responses (JSON and text)
│           │   │   ├── api_times.log                       # Run times of API calls
│           │   │   ├── config.ini.archived                 # Config snapshot for the run
│           │   │   ├── replication_report_DATE-TIME.txt    # Detailed report for this run
│           │   │   └── REPLICATION_results.csv             # AGGREGATE: Summary of all trials within a replication
│           │   ├── batch_run_log.csv                       # Log of all replication runs in an experiment
│           │   └── EXPERIMENT_results.csv                  # AGGREGATE: Summary of all replications within an experiment
│           └── STUDY_results.csv                           # AGGREGATE: Summary of all experiments in a study
|
├── docs/                       # Project documentation and diagram sources
│   ├── diagrams/               # Source files for diagrams (.mmd, .txt)
│   │   ├── architecture_data_flow.mmd
│   │   ├── architecture_experimental_logic.mmd
│   │   ├── architecture_workflow_1_run_experiment.mmd
│   │   ├── architecture_workflow_2_audit_experiment.mmd
│   │   ├── architecture_workflow_3_update_experiment.mmd
│   │   ├── architecture_workflow_4_migrate_data.mmd
│   │   ├── architecture_workflow_5_analyze_study.mmd
│   │   └── codebase_architecture.mmd
│   └── images/                 # Rendered images (.png) for the README
│   └── ...                     # (other documentation files like CONTRIBUTING.md, LICENSE.md)
|
└── tests/                      # Unit and integration tests for src/ code
    └── ...