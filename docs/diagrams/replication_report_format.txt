
================================================================================
 {<Report Title>}
================================================================================
Date:            <Run Date>
Final Status:    <pipeline_status>
Run Directory:   <run_directory_name>
Parsing Status:  <parsing_status>
Validation Status: <validation_status>
Report File:     <report_filename>

--- Run Parameters ---
Num Iterations (m): <num_iterations>
Items per Query (k): <items_per_query>
Mapping Strategy: <mapping_strategy>
Personalities Source: <db_filename>
LLM Model:       <model_name>
Run Notes:       <run_notes>
================================================================================


--- Base Query Prompt Used ---
{<base_query_prompt_content>}
-------------------------------


================================================================================
### OVERALL META-ANALYSIS RESULTS ###
================================================================================

1. Combined Significance of Score Differentiation (N=<n_valid>):
   Stouffer's Method: Combined p-value = <p_value>
   Fisher's Method: Combined p-value = <p_value>

2. Overall Magnitude of Score Differentiation (MWU Effect Size 'r') (vs Chance=0.0000):
   Mean: <mean_val>, Wilcoxon p-value: p = <p_value>

3. Overall Ranking Performance (MRR) (vs Chance=<chance_val>):
   Mean: <mean_val>, Wilcoxon p-value: p = <p_value>

4. Overall Ranking Performance (Top-1 Accuracy) (vs Chance=<chance_val>):
   Mean: <mean_val>, Wilcoxon p-value: p = <p_value>

5. Overall Ranking Performance (Top-3 Accuracy) (vs Chance=<chance_val>):
   Mean: <mean_val>, Wilcoxon p-value: p = <p_value>

6. Bias and Other Metrics:
   Top-1 Prediction Bias (StdDev of choice counts): <std_dev>
   Mean Score Difference (Correct - Incorrect): <score_diff>


<<<METRICS_JSON_START>>>
{
    "mwu_stouffer_z": <value>, 
    "mwu_stouffer_p": <value>, 
    "mwu_fisher_chi2": <value>, 
    "mwu_fisher_p": <value>, 
    "mean_effect_size_r": <value>, 
    "effect_size_r_p": <value>, 
    "mean_mrr": <value>, 
    "mrr_p": <value>, 
    "mean_top_1_acc": <value>, 
    "top_1_acc_p": <value>, 
    "mean_top_3_acc": <value>, 
    "top_3_acc_p": <value>, 
    "mean_rank_of_correct_id": <value>, 
    "rank_of_correct_id_p": <value>, 
    "top1_pred_bias_std": <value>, 
    "true_false_score_diff": <value>, 
    "bias_slope": <value>, 
    "bias_intercept": <value>, 
    "bias_r_value": <value>, 
    "bias_p_value": <value>,
    "bias_std_err": <value>,
    "n_valid_responses": <value>
}
<<<METRICS_JSON_END>>>