# Experiment Lifecycle Data Dictionary

This document is the **Experiment Lifecycle Data Dictionary** for the project. It describes the contents and structure of the `output/` directory, explaining the role of each file in the experiment execution, result aggregation, and statistical analysis workflows.

The `output/` directory contains the experimental results and statistical analyses generated by the core framework logic, building upon the foundation provided by the data preparation pipeline documented in the [üìÅ Data Preparation Data Dictionary](DATA_PREPARATION_DATA_DICTIONARY.md). For complete workflow understanding, see the [üìñ Framework Manual](../docs/FRAMEWORK_MANUAL.md) and [üöÄ Lifecycle Guide](../docs/LIFECYCLE_GUIDE.md).

{{grouped_figure:docs/diagrams/arch_project_overview.mmd | scale=2.5 | width=100% | caption=Project Architecture: The `output/` directory stores results from the core experiment and analysis logic.}}

## Scope and Transition from Data Preparation

This data dictionary picks up where the Data Preparation Data Dictionary leaves off. The key transition point is `personalities_db.txt`, which serves as the foundational database for all experiments, combined with the foundational assets that configure the experimental logic.

**Key Foundational Assets Flow:**
- `point_weights.csv` - Defines weights for astrological elements (Sun=3, Moon=3, Ascendant=3, Mercury=2, etc.)
- `balance_thresholds.csv` - Sets categorization thresholds (Elements 0.5-1.5, Signs 0.0-2.0, etc.)
- `country_codes.csv` - Maps geographic abbreviations to full country names for data validation

These files, combined with `personalities_db.txt`, feed into the experimental hierarchy to produce the results documented below.

## Experimental Hierarchy and Directory Structure

The framework organizes research into a clear four-level hierarchy, reflected in the directory structure:

```
output/
‚îú‚îÄ‚îÄ experiments/                    # Individual experiment runs
‚îÇ   ‚îî‚îÄ‚îÄ [ExperimentName_YYYYMMDD_HHMMSS]/
‚îÇ       ‚îú‚îÄ‚îÄ config.ini.archived     # Archived configuration
‚îÇ       ‚îú‚îÄ‚îÄ EXPERIMENT_results.csv  # Aggregated experiment results
‚îÇ       ‚îú‚îÄ‚îÄ EXPERIMENT_log.txt      # Experiment status log
‚îÇ       ‚îî‚îÄ‚îÄ rep-[N]_run_[timestamp]/
‚îÇ           ‚îú‚îÄ‚îÄ REPLICATION_results.csv     # Single replication results
‚îÇ           ‚îú‚îÄ‚îÄ replication_report_[timestamp].txt
‚îÇ           ‚îú‚îÄ‚îÄ replication_metrics.json    # Enhanced metrics
‚îÇ           ‚îú‚îÄ‚îÄ queries_[timestamp].txt
‚îÇ           ‚îú‚îÄ‚îÄ responses_[timestamp].txt
‚îÇ           ‚îî‚îÄ‚îÄ logs_[timestamp].txt
‚îÇ
‚îî‚îÄ‚îÄ studies/                        # Multi-experiment studies
    ‚îî‚îÄ‚îÄ [StudyName]/
        ‚îú‚îÄ‚îÄ [ExperimentA]/          # Moved from experiments/
        ‚îú‚îÄ‚îÄ [ExperimentB]/          # Moved from experiments/
        ‚îú‚îÄ‚îÄ STUDY_results.csv       # Master aggregated dataset
        ‚îî‚îÄ‚îÄ anova/                  # Statistical analysis results
            ‚îú‚îÄ‚îÄ STUDY_analysis_log.txt
            ‚îú‚îÄ‚îÄ performance_boxplots.png
            ‚îî‚îÄ‚îÄ [other analysis files]
```

## Experimental Hierarchy Levels

- **Study**: The highest-level grouping, representing a complete research question (e.g., "Performance on Random vs. Correct Mappings")
- **Experiment**: A complete set of runs for a single experimental condition (e.g., "Gemini 2.0 Flash with k=10 Subjects")
- **Replication**: A single, complete run of an experiment, typically repeated 30 times for statistical power
- **Trial**: An individual matching task performed within a replication, typically repeated 100 times

{{grouped_figure:docs/diagrams/data_main_flow.mmd | scale=2.5 | width=80% | caption=Data Flow Diagram: Creation and transformation of data artifacts through the experiment workflow.}}

## File Descriptions by Hierarchy Level

### 1. Replication Level Files

Each replication creates several files that capture the complete execution and results of a single experimental run.

#### Core Result Files

**`REPLICATION_results.csv`** - Single-row summary with exact column order defined in `config.ini`:
```
run_directory,replication,n_valid_responses,model,mapping_strategy,temperature,k,m,db,
mean_mrr,mrr_p,mean_top_1_acc,top_1_acc_p,mean_top_3_acc,top_3_acc_p,
mean_mrr_lift,mean_top_1_acc_lift,mean_top_3_acc_lift,
mean_rank_of_correct_id,rank_of_correct_id_p,top1_pred_bias_std,true_false_score_diff,
bias_slope,bias_intercept,bias_r_value,bias_p_value,bias_std_err
```

**Column Categories:**
- **Configuration**: `run_directory`, `replication`, `model`, `mapping_strategy`, `temperature`, `k`, `m`, `db`
- **Core Performance**: `mean_mrr`, `mrr_p`, `mean_top_1_acc`, `top_1_acc_p`, `mean_top_3_acc`, `top_3_acc_p`
- **Lift Metrics**: `mean_mrr_lift`, `mean_top_1_acc_lift`, `mean_top_3_acc_lift`
- **Positional Analysis**: `mean_rank_of_correct_id`, `rank_of_correct_id_p`
- **Bias Analysis**: `bias_slope`, `bias_intercept`, `bias_r_value`, `bias_p_value`, `bias_std_err`, `top1_pred_bias_std`, `true_false_score_diff`
- **Quality Control**: `n_valid_responses`

**`replication_metrics.json`** - Enhanced JSON metrics with comprehensive analysis results:
```json
{
  "mean_mrr": 0.1234,
  "median_mrr": 0.1156,
  "mrr_p": 0.0567,
  "mean_top_1_acc": 0.0890,
  "median_top_1_acc": 0.0823,
  "top_1_acc_p": 0.1234,
  "mean_top_3_acc": 0.2345,
  "median_top_3_acc": 0.2201,
  "top_3_acc_p": 0.0123,
  "mean_mrr_lift": 1.456,
  "mean_top_1_acc_lift": 1.234,
  "mean_top_3_acc_lift": 1.567,
  "mean_rank_of_correct_id": 5.67,
  "rank_of_correct_id_p": 0.0890,
  "n_valid_responses": 100,
  "positional_bias_metrics": {
    "bias_slope": -0.0123,
    "bias_intercept": 0.456,
    "bias_r_value": -0.234,
    "bias_p_value": 0.0567,
    "bias_std_err": 0.0089,
    "top1_pred_bias_std": 0.123,
    "true_false_score_diff": 0.0234
  }
}
```

**Key Metric Explanations:**
- **Lift Metrics**: Performance relative to chance (e.g., `mean_mrr_lift = actual_mrr / chance_mrr`)
- **Positional Bias**: Linear trend analysis detecting systematic position preferences over trial sequence
- **Bias Analysis**: Standard deviation of top-1 predictions across positions and true vs. false match scoring differences

**Statistical Assumptions and Chance Level Calculations:**

The framework calculates chance levels under the null hypothesis of uniform random selection across k possible positions:

- **MRR Chance**: `(1/k) √ó Œ£(1/j)` for j=1 to k (harmonic mean of reciprocal ranks)
- **Top-K Accuracy Chance**: `min(K, k) / k` (probability of correct answer in top K positions)
- **Mean Rank Chance**: `(k + 1) / 2` (expected rank under uniform distribution)

**Statistical Test Directionality:**
- **Performance metrics** (MRR, Top-K accuracy): Use `alternative='greater'` (higher values indicate better performance)
- **Rank metrics** (mean rank of correct ID): Use `alternative='less'` (lower ranks indicate better performance)

All statistical tests use the Wilcoxon signed-rank test for non-parametric comparison against theoretical chance levels, with Benjamini-Hochberg FDR correction applied across multiple comparisons.

#### Execution Artifacts

**`replication_report_[timestamp].txt`** - Human-readable summary with parsing diagnostics and embedded JSON metrics:

```
================================================================================
### OVERALL META-ANALYSIS RESULTS ###
================================================================================
Number of Valid Responses: 100

--- Response Parsing Summary ---
llm_response_001.txt: SUCCESS - parsed matrix
llm_response_002.txt: SUCCESS - parsed matrix
llm_response_003.txt: REJECTED - parsing failed
llm_response_004.txt: SUCCESS - parsed matrix
llm_response_005.txt: SUCCESS - parsed matrix
llm_response_006.txt: SUCCESS - parsed matrix

1. Overall Ranking Performance (MRR) (vs Chance=0.100):
   Mean: 0.156, Wilcoxon p-value: p = 0.001

2. Overall Ranking Performance (Top-1 Accuracy) (vs Chance=0.100):
   Mean: 0.089, Wilcoxon p-value: p = 0.023

3. Overall Ranking Performance (Top-3 Accuracy) (vs Chance=0.300):
   Mean: 0.234, Wilcoxon p-value: p = 0.012

4. Bias and Other Metrics:
   Top-1 Prediction Bias (StdDev of choice counts): 0.123
   Mean Score Difference (Correct - Incorrect): 0.034

<<<METRICS_JSON_START>>>
{
  "mean_mrr": 0.156,
  "mrr_p": 0.001,
  "mean_top_1_acc": 0.089,
  "top_1_acc_p": 0.023,
  "mean_top_3_acc": 0.234,
  "top_3_acc_p": 0.012,
  "mean_mrr_lift": 1.56,
  "mean_top_1_acc_lift": 0.89,
  "mean_top_3_acc_lift": 0.78,
  "mean_rank_of_correct_id": 6.42,
  "rank_of_correct_id_p": 0.005,
  "top1_pred_bias_std": 0.123,
  "true_false_score_diff": 0.034,
  "bias_slope": -0.012,
  "bias_intercept": 0.456,
  "bias_r_value": -0.234,
  "bias_p_value": 0.067,
  "bias_std_err": 0.009,
  "n_valid_responses": 100,
  "positional_bias_metrics": {
    "top1_pred_bias_std": 0.123,
    "true_false_score_diff": 0.034
  }
}
<<<METRICS_JSON_END>>>
```

**Report Structure:**
- **Run parameters and configuration** with timestamps and model details
- **Response parsing diagnostics** showing success/failure status for each trial
- **Human-readable summary** with performance vs. chance comparisons
- **Embedded JSON block** with exact delimiters for programmatic extraction
- **Bias analysis results** integrated into both text and JSON sections

**`queries_[timestamp].txt`** - LLM queries sent during the replication
**`responses_[timestamp].txt`** - Raw LLM responses received  
**`logs_[timestamp].txt`** - Detailed execution logs and debugging information

### 2. Experiment Level Files

Experiment-level files aggregate data from all replications within a single experimental condition.

**`EXPERIMENT_results.csv`** - Multi-row file with one row per replication, containing all columns from REPLICATION_results.csv. Created by `compile_experiment_results.py`.

**`EXPERIMENT_log.txt`** - Summary log showing batch execution status, including completion summary and any error reports.

**`config.ini.archived`** - Complete snapshot of configuration parameters ensuring reproducibility:
```ini
[LLM]
model = gemini-2.0-flash-exp
temperature = 0.7
api_endpoint = https://openrouter.ai/api/v1/chat/completions

[Experiment]
mapping_strategy = correct
k = 10
m = 100

[Experiment]
k_per_query = 10
num_iterations = 100

[Schema]
factors = model, mapping_strategy, temperature, k, m
metrics = mean_mrr,mean_top_1_acc,mean_top_3_acc,mean_mrr_lift,...
csv_header_order = run_directory,replication,n_valid_responses,model,...

[ModelNormalization]
google-gemini-2-0-flash = gemini-2.0-flash, gemini_2_0_flash
openai-gpt-4o-mini = gpt-4o-mini, gpt_4o_mini
...
```

**Key Configuration Sections:**
- **LLM**: Model selection, temperature, API configuration
- **Experiment/Study**: Core experimental parameters (k, m, mapping strategy)
- **Schema**: Column definitions and ordering for CSV output standardization
- **ModelNormalization**: Canonical naming for model variants

### 3. Study Level Files

Study-level files provide master aggregation and statistical analysis across all experiments in a research question.

**`STUDY_results.csv`** - Master dataset containing all rows from all EXPERIMENT_results.csv files in the study. Created by `compile_study_results.py`.

#### Statistical Analysis Directory (`anova/`)

**`STUDY_analysis_log.txt`** - Complete statistical analysis with standardized format:

```
=========================================================================
       LLM Narrative Framework: Comprehensive Statistical Analysis
=========================================================================

ANALYSIS FOR METRIC: 'Mean Reciprocal Rank (MRR)'
================================================================================
Detected 2 active factor(s) with variation: model, mapping_strategy

--- Descriptive Statistics by model, mapping_strategy ---
                                              Replications  Total Trials (N)   Mean  Std. Dev.
google-gemini-2-0-flash     correct                     30            3000  0.156     0.023
google-gemini-2-0-flash     random                      30            3000  0.102     0.018

--- ANOVA Summary for Mean Reciprocal Rank (MRR) ---
                      sum_sq         df         F   PR(>F)   eta_sq
C(model)              0.023      1.000    12.45    0.001    0.172
C(mapping_strategy)   0.089      1.000    48.23    0.000    0.451
Residual              0.108     58.000       NaN      NaN    0.377

--- Post-Hoc Analysis ---
Multiple Comparison of Means - Tukey HSD, FWER=0.05
==============================================================================================
           group1                      group2           meandiff p-adj   lower   upper  reject
----------------------------------------------------------------------------------------------
correct                         random                    0.054  0.000   0.041   0.067    True

--- Performance Groups ---
Performance Group Median Score     Models
          Group 1       0.156      google-gemini-2-0-flash (correct)
          Group 2       0.102      google-gemini-2-0-flash (random)
```

**Key Format Features:**
- **ANOVA Tables**: Include `sum_sq`, `df`, `F`, `PR(>F)`, `eta_sq` columns with FDR correction
- **Post-hoc Testing**: Tukey HSD results with family-wise error rate (FWER) control
- **Performance Grouping**: Models grouped by statistical equivalence
- **Factor Analysis**: Automatic detection of experimental factors with variation

**`performance_boxplots.png`** - Visualization of performance distributions across experimental conditions

**Additional Analysis Files** - Various statistical outputs, diagnostic plots, and supplementary analysis results

## CSV Schema and Column Definitions

The hierarchical CSV structure follows a standardized schema defined in `config.ini` section `[Schema]`. The `csv_header_order` parameter ensures all CSV files share identical column structure for seamless aggregation:

```ini
csv_header_order = run_directory,replication,n_valid_responses,model,mapping_strategy,temperature,k,m,db,mean_mrr,mrr_p,mean_top_1_acc,top_1_acc_p,mean_top_3_acc,top_3_acc_p,mean_mrr_lift,mean_top_1_acc_lift,mean_top_3_acc_lift,mean_rank_of_correct_id,rank_of_correct_id_p,top1_pred_bias_std,true_false_score_diff,bias_slope,bias_intercept,bias_r_value,bias_p_value,bias_std_err
```

### Detailed Column Definitions

#### Core Configuration Columns
- `run_directory` - Unique identifier for the replication run (e.g., "rep-1_run_20250101_120000")
- `replication` - Replication number within the experiment (integer)
- `model` - Canonical LLM model name (e.g., "google-gemini-2-0-flash")
- `mapping_strategy` - Experimental condition ("correct" or "random")
- `temperature` - LLM temperature parameter (float, typically 0.0-1.0)
- `k` - Number of subjects in experiment (integer)
- `m` - Number of trials per replication (integer)
- `db` - Database identifier (typically "personalities_db.txt")

#### Primary Performance Metrics
- `mean_mrr` - Mean Reciprocal Rank across all trials (float, 0.0-1.0)
- `median_mrr` - Median Reciprocal Rank across all trials (float, 0.0-1.0)
- `mrr_p` - P-value for MRR Wilcoxon signed-rank test against chance
- `mean_top_1_acc` - Mean Top-1 accuracy (exact matches, float 0.0-1.0)
- `median_top_1_acc` - Median Top-1 accuracy (float, 0.0-1.0)
- `top_1_acc_p` - P-value for Top-1 accuracy test
- `mean_top_3_acc` - Mean Top-3 accuracy (float 0.0-1.0)
- `median_top_3_acc` - Median Top-3 accuracy (float, 0.0-1.0)
- `top_3_acc_p` - P-value for Top-3 accuracy test

#### Enhanced Performance Metrics (Lift Analysis)
- `mean_mrr_lift` - Lift calculation: actual_mrr / chance_mrr
- `mean_top_1_acc_lift` - Lift calculation: actual_top1 / chance_top1
- `mean_top_3_acc_lift` - Lift calculation: actual_top3 / chance_top3

#### Positional and Bias Analysis
- `bias_slope` - Linear trend slope for positional bias detection (systematic position drift over trials)
- `bias_intercept` - Linear regression intercept
- `bias_r_value` - Correlation coefficient for bias analysis
- `bias_p_value` - P-value for bias significance test
- `bias_std_err` - Standard error of bias measurement
- `mean_rank_of_correct_id` - Average rank of correct answer across all trials
- `rank_of_correct_id_p` - P-value for rank analysis (Wilcoxon signed-rank test)
- `top1_pred_bias_std` - Standard deviation of top-1 predictions across all possible positions
- `true_false_score_diff` - Mean difference between scores for true matches vs. false matches

#### Quality Control Metrics
- `n_valid_responses` - Number of valid LLM responses successfully processed (integer)

## Statistical Analysis and FDR Correction

The framework implements False Discovery Rate (FDR) correction across all statistical tests. ANOVA tables include both raw p-values and FDR-corrected `p-corr` columns:

```
Factor          F-stat    p-value    p-corr    Significance
mapping_strategy  12.34     0.001     0.003        ***
model             5.67     0.020     0.040         *
interaction       2.34     0.130     0.150         ns
```

Post-hoc testing and performance grouping follow similar correction procedures, ensuring robust statistical inference.

## Configuration Management and Reproducibility

Each experiment automatically archives its complete configuration state in `config.ini.archived`. This provides:

- **Parameter Tracking** - Complete record of all experimental parameters
- **Reproducibility** - Ability to exactly recreate any experiment
- **Provenance** - Clear audit trail linking results to their generating conditions
- **Reprocessing** - Capability to re-run analysis without repeating expensive LLM calls

## Report Formats and Integration

The framework generates multiple report formats optimized for different use cases:

- **Machine-readable CSVs** - For further analysis and data processing
- **Human-readable logs** - For research review and documentation  
- **Embedded JSON blocks** - For detailed metric extraction and validation
- **Statistical summaries** - For publication and presentation

All reports maintain consistent terminology and cross-reference capabilities, enabling seamless integration across the analysis pipeline.

## Transition to Statistical Analysis

The experiment workflow culminates in the `STUDY_results.csv` master dataset and associated statistical analysis in the `anova/` directory. These provide the final, publication-ready results for the research question, complete with statistical significance testing and comprehensive diagnostic evaluation.

For detailed information about the data preparation that feeds into this workflow, see the **[üìÅ Data Preparation Data Dictionary](DATA_PREPARATION_DATA_DICTIONARY.md)**. For comprehensive workflow documentation, see the **[üìñ Framework Manual](../docs/FRAMEWORK_MANUAL.md)** and **[üöÄ Lifecycle Guide](../docs/LIFECYCLE_GUIDE.md)**.