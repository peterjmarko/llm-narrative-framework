[build-system]
requires = ["pdm-backend"]
build-backend = "pdm.backend"

[project]
name = "llm-personality-matching"
version = "9.1.1"
description = "A reproducible pipeline for LLM personality matching experiments."
authors = [
    {name = "Peter Marko", email = "peter.j.marko@gmail.com"},
]
requires-python = ">=3.11"
readme = "README.md"
license = {text = "MIT"}

dependencies = [
    "numpy",
    "pandas",
    "scipy",
    "statsmodels",
    "networkx",
    "requests>=2.32.4",
    "python-dotenv",
    "tqdm>=4.67.1",
    "seaborn",
    "matplotlib",
    "pingouin>=0.5.5",
    "thefuzz[speedup]>=0.22.1",
    "beautifulsoup4>=4.13.4",
    "certifi>=2025.8.3",
]

[tool.pdm]
# This tells PDM to use a virtual environment located in the project's .venv folder.
venv.in-project = true

[tool.pytest.ini_options]
pythonpath = ["src"]

[tool.pdm.scripts]
# Development and testing shortcuts. {args} allows passing specific files.
# This is the main entry point for all tests (Python and PowerShell).
test = {cmd = "python tests/run_all_tests.py {args}", help = "Run all tests (Python and PowerShell) with cleanup."}

# --- Definitive Coverage Workflow ---
# This is the robust, explicit workflow for subprocess testing. It has 5 steps:
# 1. Erase old data.
# 2. Use `coverage run` as the main entry point to start the test session.
# 3. Your test helper also calls `coverage run` for the subprocess.
#    (This creates parallel data files thanks to your .coveragerc)
# 4. `coverage combine` merges all parallel data into one file.
# 5. `coverage report` or `coverage html` shows the final, correct results.

# --- THE DEFINITIVE COVERAGE SCRIPTS ---
# We disable the pytest-cov plugin with `-p no:cov` to prevent it from
# interfering with our manual `coverage run` invocation.
cov = {shell = "coverage erase && coverage run -m pytest -p no:cov && coverage report", help="Run all tests with coverage analysis."}
cov-prep = {shell = "coverage erase && coverage run -m pytest -p no:cov tests/data_preparation/ && coverage report", help="Run coverage for the data preparation test suite."}
cov-file = {shell = "coverage erase && coverage run -m pytest -p no:cov {args} && coverage report", help="Run coverage for a specific test file by its full path (e.g., tests/data_preparation/test_select_eligible_candidates.py)."}
cov-html = {shell = "coverage erase && coverage run -m pytest -p no:cov && coverage html", help="Run all tests and generate an HTML coverage report."}
cov-erase = {cmd = "coverage erase", help="Clean up coverage data files."}
# ------------------------------------

gen-scope-report = "python scripts/generate_scope_report.py"
lint = "pdm run lint-headers && pdm run lint-docstrings"
lint-headers = {cmd = "python scripts/lint_file_headers.py --fix ./src/*.py ./tests/*.py ./*.ps1 ./scripts/*.py", help = "Fix headers and footers on all project scripts."}
check-headers = {cmd = "python scripts/lint_file_headers.py ./src/*.py ./tests/*.py ./*.ps1 ./scripts/*.py", help = "Check headers and footers on all project scripts."}
build-docs = "python scripts/build_docs.py"

# --- Developer Workflow ---
commit = {cmd = "cz commit", help = "Create a new commit using the interactive Commitizen prompt."}
release = {cmd = "python scripts/finalize_release.py", help = "Finalize a new release (bump, changelog, tag)."}
# ------------------------

# Data preparation workflow shortcuts
prep-data = "pwsh -ExecutionPolicy Bypass -File ./prepare_data.ps1"

# Main workflow shortcuts
new-exp = "pwsh -ExecutionPolicy Bypass -File ./new_experiment.ps1"
aud-exp = "pwsh -ExecutionPolicy Bypass -File ./audit_experiment.ps1"
fix-exp = "pwsh -ExecutionPolicy Bypass -File ./fix_experiment.ps1"
mig-exp = "pwsh -ExecutionPolicy Bypass -File ./migrate_experiment.ps1"
pro-stu = "pwsh -ExecutionPolicy Bypass -File ./process_study.ps1"
new-stu = "pwsh -ExecutionPolicy Bypass -File ./new_study.ps1"
aud-stu = "pwsh -ExecutionPolicy Bypass -File ./audit_study.ps1"
fix-stu = "pwsh -ExecutionPolicy Bypass -File ./fix_study.ps1"
mig-stu = "pwsh -ExecutionPolicy Bypass -File ./migrate_study.ps1"

# --- Python Unit Tests ---
test-py-data-prep = {cmd = "pytest tests/data_preparation/", help = "Run all data preparation unit tests."}
test-py-exp = {cmd = "pytest tests/experiment_pipeline/", help = "Run all experiment pipeline unit tests."}
test-assembly = {cmd = "pytest tests/data_preparation/test_assembly_algorithm.py", help = "Run the core assembly algorithm integration test."}

# --- Integration Tests (All Layers) ---
test-l2 = "pwsh -File ./tests/testing_harness/data_preparation/layer2/run_layer2_test.ps1"
test-l3-default = "pwsh ./tests/testing_harness/data_preparation/layer3/run_layer3_test.ps1 -Profile default"
test-l3-bypass = "pwsh ./tests/testing_harness/data_preparation/layer3/run_layer3_test.ps1 -Profile bypass"
test-l3-interactive = "pwsh ./tests/testing_harness/data_preparation/layer3/run_layer3_test.ps1 -Profile default -Interactive"
test-l4 = "pwsh -File ./tests/testing_harness/experiment_pipeline/layer4/run_layer4_test.ps1"
test-l5 = "pwsh -File ./tests/testing_harness/experiment_pipeline/layer5/run_layer5_test.ps1"

# --- PowerShell Pester Tests (By Suite) ---
# Experiment Lifecycle
test-ps-new-exp = "pwsh ./tests/experiment_pipeline/new_experiment.Tests.ps1"
test-ps-audit-exp = "pwsh ./tests/experiment_pipeline/audit_experiment.Tests.ps1"
test-ps-fix-exp = "pwsh ./tests/experiment_pipeline/fix_experiment.Tests.ps1"
test-ps-migr-exp = "pwsh ./tests/experiment_pipeline/migrate_experiment.Tests.ps1"
test-ps-exp = {composite = ["test-ps-new-exp", "test-ps-audit-exp", "test-ps-fix-exp", "test-ps-migr-exp"], help = "Run all PowerShell tests for the experiment lifecycle."}
# Study Lifecycle
test-ps-comp-study = "pwsh ./tests/compile_study.Tests.ps1"
test-ps-new-study = "pwsh ./tests/new_study.Tests.ps1"
test-ps-audit-study = "pwsh ./tests/audit_study.Tests.ps1"
test-ps-fix-study = "pwsh ./tests/fix_study.Tests.ps1"
test-ps-migr-study = "pwsh ./tests/migrate_study.Tests.ps1"
# Composite Runners
test-ps-all = "pwsh ./tests/run_all_ps_tests.ps1"
test-exp-all = {composite = ["test-py-exp", "test-ps-exp"], help = "Run all Python and PowerShell tests for the experiment lifecycle."}

[tool.commitizen]
name = "cz_conventional_commits"
version = "9.1.1"
version_files = [
    "pyproject.toml:version"
]
tag_format = "v$version"
changelog_file = "CHANGELOG.md"
changelog_format = "keep_a_changelog"

[dependency-groups]
dev = [
    "pytest",
    "pre-commit",
    "pypandoc>=1.15",
    "pillow>=10.4.0",
    "pytest-cov>=5.0.0",
    "pytest-mock>=3.14.1",
    "commitizen>=3.31.0",
]
