[build-system]
requires = ["pdm-backend"]
build-backend = "pdm.backend"

[project]
name = "llm-narrative-framework"
version = "10.5.0"
description = "A reproducible pipeline for LLM personality matching experiments."
authors = [
    {name = "Peter J. Marko", email = "peter.j.marko@gmail.com"},
]
requires-python = ">=3.11"
readme = "README.md"
license = {text = "MIT"}

dependencies = [
    "numpy",
    "pandas",
    "scipy",
    "statsmodels",
    "networkx",
    "requests>=2.32.4",
    "python-dotenv",
    "tqdm>=4.67.1",
    "seaborn",
    "matplotlib",
    "pingouin>=0.5.5",
    "thefuzz[speedup]>=0.22.1",
    "beautifulsoup4>=4.13.4",
    "certifi>=2025.8.3",
]

[tool.pdm]
# This tells PDM to use a virtual environment located in the project's .venv folder.
venv.in-project = true

[tool.pytest.ini_options]
pythonpath = ["src"]

[tool.pdm.scripts]
# ==============================================================================
# === PRIMARY TEST RUNNERS ===
# ==============================================================================
# This is the main entry point for all tests (Python and PowerShell).
test = {cmd = "python tests/run_all_tests.py {args}", help = "Run all tests (Python and PowerShell) with cleanup."}
cov = {shell = "pytest --cov=src --cov-report=term-missing", help = "Run all tests with coverage analysis."}
test-cov = {shell = "pytest --cov=src --cov-report= {args}", help = "Run tests for a specific file to update .coverage data."}
report-cov = {shell = "coverage report -m --no-skip-covered {args}", help = "Generate a focused coverage report for specific source file(s)."}
cov-html = {shell = "pytest --cov=src --cov-report=html", help = "Run all tests and generate an HTML coverage report."}

# ==============================================================================
# === MAINTENANCE, LINTING & REPORTING ===
# ==============================================================================
clean = {cmd = "python scripts/maintenance/clean_project.py", help = "Clean up temporary and generated files."}
scope-report = "python scripts/maintenance/generate_scope_report.py"
list-files = "python scripts/maintenance/list_project_files.py"
sync-project = "python scripts/maintenance/sync_project_assets.py"
txt-copy = "python scripts/maintenance/convert_py_to_txt.py"
lint = {composite = ["check-headers", "lint-docstrings"], help="Run all read-only linting checks."}
lint-fix = {composite = ["lint-headers-fix", "lint-docstrings"], help="Run all linters and apply automatic fixes."}
check-headers = {cmd = "python scripts/lint/lint_file_headers.py", help = "Check headers and footers on all project scripts."}
lint-headers-fix = {cmd = "python scripts/lint/lint_file_headers.py --fix", help = "Fix headers and footers on all project scripts."}
lint-docstrings = {cmd = "python scripts/lint/lint_docstrings.py {args}", help = "Check all scripts for docstring compliance (--deep for full scan)."}

# ==============================================================================
# === BUILD & RELEASE WORKFLOW ===
# ==============================================================================
build-docs = "python scripts/build/build_docs.py"
commit = {cmd = "cz commit", help = "Create a new commit using the interactive Commitizen prompt."}
release = {cmd = "python scripts/build/finalize_release.py", help = "Finalize a new release (bump, changelog, tag)."}

# ==============================================================================
# === CORE PROJECT WORKFLOWS ===
# ==============================================================================
# Data preparation workflow shortcuts
prep-data = "pwsh -ExecutionPolicy Bypass -File ./prepare_data.ps1"
# Main workflow shortcuts
new-exp = "pwsh -ExecutionPolicy Bypass -File ./new_experiment.ps1"
aud-exp = "pwsh -ExecutionPolicy Bypass -File ./audit_experiment.ps1"
fix-exp = "pwsh -ExecutionPolicy Bypass -File ./fix_experiment.ps1"
com-stu = "pwsh -ExecutionPolicy Bypass -File ./compile_study.ps1"
aud-stu = "pwsh -ExecutionPolicy Bypass -File ./audit_study.ps1"

# ==============================================================================
# === DETAILED TEST SUITES ===
# ==============================================================================
# --- Python Unit Tests ---
test-data-prep = {cmd = "pytest tests/data_preparation/", help = "Run all data preparation unit tests."}
test-exp-lc = {cmd = "pytest tests/experiment_lifecycle/", help = "Run all experiment lifecycle unit tests."}
cov-exp-lc = {shell = "coverage erase && coverage run -m pytest -p no:cov tests/experiment_lifecycle/ && coverage report --skip-covered", help = "Run experiment lifecycle tests with a focused coverage report."}
test-assembly = {cmd = "pytest tests/algorithm_validation/test_profile_generation_algorithm.py", help = "Run the core assembly algorithm integration test."}
test-cov-report = {cmd = "pwsh -File ./scripts/testing/run_targeted_coverage.ps1 {args}", help = "Run a test file and generate a focused coverage report for its corresponding source file."}

# --- Integration Tests (All Layers) ---
test-l2 = "pwsh -File ./tests/testing_harness/data_preparation/layer2/run_layer2_test.ps1"
test-l3 = "pwsh ./tests/testing_harness/data_preparation/layer3/run_layer3_test.ps1 -Profile default"
test-l3-interactive = "pwsh ./tests/testing_harness/data_preparation/layer3/run_layer3_test.ps1 -Profile default -Interactive"
test-l3-bypass = "pwsh ./tests/testing_harness/data_preparation/layer3/run_layer3_test.ps1 -Profile bypass"
test-l3-selection = "pwsh ./tests/algorithm_validation/validate_selection_algorithms.ps1"
test-l4 = "pwsh -File ./tests/testing_harness/experiment_lifecycle/layer4/run_layer4_test.ps1"
test-l4-interactive = "pwsh -File ./tests/testing_harness/experiment_lifecycle/layer4/run_layer4_test.ps1 -Interactive"
test-l5 = "pwsh -File ./tests/testing_harness/experiment_lifecycle/layer5/run_layer4_test.ps1"
test-query-gen = "pwsh -File ./tests/testing_harness/validate_query_generation.ps1"
test-stats-reporting = "pwsh -File ./tests/testing_harness/validate_statistical_reporting.ps1"

# --- PowerShell Tests (By Suite) ---
# Experiment Lifecycle
test-ps-new-exp = "pwsh ./tests/experiment_lifecycle/new_experiment.Tests.ps1"
test-ps-audit-exp = "pwsh ./tests/experiment_lifecycle/audit_experiment.Tests.ps1"
test-ps-fix-exp = "pwsh ./tests/experiment_lifecycle/fix_experiment.Tests.ps1"
test-ps-exp = {composite = ["test-ps-new-exp", "test-ps-audit-exp", "test-ps-fix-exp", "test-ps-migr-exp"], help = "Run all PowerShell tests for the experiment lifecycle."}
# Study Lifecycle
test-ps-comp-study = "pwsh ./tests/experiment_lifecycle/compile_study.Tests.ps1"
test-ps-audit-study = "pwsh ./tests/experiment_lifecycle/audit_study.Tests.ps1"
# Composite Runners
test-ps-all = "pwsh ./tests/run_all_ps_tests.ps1"
test-exp-all = {composite = ["test-py-exp", "test-ps-exp"], help = "Run all Python and PowerShell tests for the experiment lifecycle."}

[tool.commitizen]
name = "cz_conventional_commits"
version = "10.5.0"
version_files = [
    "pyproject.toml:version"
]
tag_format = "v$version"
changelog_file = "CHANGELOG.md"
changelog_format = "keep_a_changelog"

[tool.coverage.run]
source = ["src"]
omit = ["*/__init__.py"]

[tool.coverage.report]
show_missing = true
skip_covered = false
exclude_lines = [
    "pragma: no cover",
    "if __name__ == .__main__.:",
]

[dependency-groups]
dev = [
    "pytest",
    "pre-commit",
    "pypandoc>=1.15",
    "pillow>=10.4.0",
    "pytest-cov>=5.0.0",
    "pytest-mock>=3.14.1",
    "commitizen>=3.31.0",
    "python-docx>=1.2.0",
]

[tool.pylance.exclude]
# Add other folders as needed, e.g., "**/node_modules"
exclude = [
    "**/__pycache__",
    "**/.venv",
    "**/output",
    "**/data/backup",
    "**/temp_test_environment",
    "**/_archive",
    "**/htmlcov"
]