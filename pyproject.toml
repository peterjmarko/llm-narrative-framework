[build-system]
requires = ["pdm-backend"]
build-backend = "pdm.backend"

[project]
name = "llm-narrative-framework"
version = "16.1.2"
description = "A reproducible pipeline for LLM personality matching experiments."
authors = [
    {name = "Peter J. Marko", email = "peter.j.marko@gmail.com"},
]
requires-python = ">=3.11"
readme = "README.md"
license = {text = "MIT"}

dependencies = [
    "numpy",
    "pandas",
    "scipy",
    "statsmodels",
    "networkx",
    "requests>=2.32.4",
    "python-dotenv",
    "tqdm>=4.67.1",
    "seaborn",
    "matplotlib",
    "pingouin>=0.5.5",
    "thefuzz[speedup]>=0.22.1",
    "beautifulsoup4>=4.13.4",
    "certifi>=2025.8.3",
    "colorama>=0.4.6",
]

[tool.pytest.ini_options]
pythonpath = ["src"]
testpaths = ["tests"]
addopts = [
    "--ignore=tests/archive",
    "--ignore=tests/_archive",
    "--ignore=linter_backups",
    "--ignore=_archive",
    "--ignore=tests/scripts/test_clean_project.py",
    "--ignore=tests/test_build_docs.py",
    "--ignore=tests/test_convert_py_to_txt.py",
    "--ignore=tests/test_list_project_files.py",
    "--ignore=tests/test_robustness.py",
    "--ignore=tests/test_smoke.py"
]

[tool.commitizen]
name = "cz_conventional_commits"
version = "16.1.2"
version_files = [
    "pyproject.toml:version"
]
tag_format = "v$version"
changelog_file = "CHANGELOG.md"
changelog_format = "keep_a_changelog"

[tool.coverage.run]
source = ["src"]
omit = ["*/__init__.py"]

[tool.coverage.report]
show_missing = true
skip_covered = false
exclude_lines = [
    "pragma: no cover",
    "if __name__ == .__main__.:",
]


[tool.pdm.venv]
in-project = true

[tool.pdm.scripts]
# ==============================================================================
# === LOCK MANAGEMENT ===
# ==============================================================================
unlock = {cmd = "python scripts/maintenance/unlock.py", help = "Remove stale operation lock (emergency use only)."}

# ==============================================================================
# === MAINTENANCE, LINTING & REPORTING ===
# ==============================================================================
clean = {cmd = "python scripts/maintenance/clean_project.py", help = "Clean up temporary and generated files."}
scope-report = "python scripts/maintenance/generate_scope_report.py"
list-files = "python scripts/maintenance/list_project_files.py"
sync-project = "python scripts/maintenance/sync_project_assets.py"
txt-copy = "python scripts/maintenance/convert_py_to_txt.py"
lint = {composite = ["check-headers", "lint-docstrings"], help="Run all read-only linting checks."}
lint-fix = {composite = ["lint-headers-fix", "lint-docstrings"], help="Run all linters and apply automatic fixes."}
check-headers = {cmd = "python scripts/lint/lint_file_headers.py", help = "Check headers and footers on all project scripts."}
lint-headers-fix = {cmd = "python scripts/lint/lint_file_headers.py --fix", help = "Fix headers and footers on all project scripts."}
lint-docstrings = {cmd = "python scripts/lint/lint_docstrings.py {args}", help = "Check all scripts for docstring compliance (--deep for full scan)."}

# ==============================================================================
# === BUILD & RELEASE WORKFLOW ===
# ==============================================================================
build-docs = "python scripts/build/build_docs.py"
commit = {cmd = "cz commit", help = "Create a new commit using the interactive Commitizen prompt."}
release = {cmd = "python scripts/build/finalize_release.py", help = "Finalize a new release (bump, changelog, tag)."}

# ==============================================================================
# === DATA PREPARATION WORKFLOW ===
# ==============================================================================
prep-data = {shell = "python scripts/maintenance/operation_runner.py prep-data pwsh -ExecutionPolicy Bypass -File ./prepare_data.ps1", help = "Run the full data preparation pipeline."}

# ==============================================================================
# === CORE EXPERIMENT WORKFLOWS ===
# ==============================================================================
# Main workflow shortcuts
new-exp = {shell = "python scripts/maintenance/operation_runner.py new-exp pwsh -ExecutionPolicy Bypass -File ./new_experiment.ps1"}
audit-exp = {shell = "python scripts/maintenance/operation_runner.py aud-exp pwsh -ExecutionPolicy Bypass -File ./audit_experiment.ps1"}
fix-exp = {shell = "python scripts/maintenance/operation_runner.py fix-exp pwsh -ExecutionPolicy Bypass -File ./fix_experiment.ps1"}
compile-study = {shell = "python scripts/maintenance/operation_runner.py com-stu pwsh -ExecutionPolicy Bypass -File ./compile_study.ps1"}
audit-study = {shell = "python scripts/maintenance/operation_runner.py aud-stu pwsh -ExecutionPolicy Bypass -File ./audit_study.ps1"}

# ==============================================================================
# === TESTING WORKFLOW (Organized by Typical Testing Sequence) ===
# ==============================================================================
# For the complete testing workflow and sequence details, see:
# docs/TESTING_GUIDE.md - "Typical Testing Sequence" section
#
# IMPORTANT: Section headers (marked with ===) are used by operation_runner.py
# to categorize operations for audit logging. Maintain clear section boundaries:
# - "TESTING" → test_summary.jsonl
# - "DATA PREPARATION" → data_prep_summary.jsonl
# - "CORE EXPERIMENT" → workflow_summary.jsonl

# --- Stage 0: Infrastructure Tests ---
test-op-runner = {shell = "python scripts/maintenance/operation_runner.py test-op-runner pytest tests/maintenance/test_operation_runner.py", help = "Test the operation runner itself."}
test-restore-backup = {shell = "python scripts/maintenance/operation_runner.py test-restore-backup pwsh -File ./tests/test_restore_data_backup.ps1", help = "Test the data pipeline's backup and restore functionality."}

# --- Stage 1: Unit Tests - Data Preparation Pipeline ---
test-data-prep = {shell = "python scripts/maintenance/operation_runner.py test-data-prep pytest tests/data_preparation/", help = "Run all data preparation unit tests."}

# --- Stage 2: Data Pipeline Integration (Layer 2-3) ---
test-l2 = {shell = "python scripts/maintenance/operation_runner.py test-l2 pwsh -File ./tests/testing_harness/data_preparation/layer2/run_layer2_test.ps1"}
test-l3 = {shell = "python scripts/maintenance/operation_runner.py test-l3 pwsh ./tests/testing_harness/data_preparation/layer3/run_layer3_test.ps1 -Profile default"}
test-l3-bypass = {shell = "python scripts/maintenance/operation_runner.py test-l3-bypass pwsh ./tests/testing_harness/data_preparation/layer3/run_layer3_test.ps1 -Profile bypass"}
test-l3-interactive = {shell = "python scripts/maintenance/operation_runner.py test-l3-interactive pwsh ./tests/testing_harness/data_preparation/layer3/run_layer3_test.ps1 -Profile default -Interactive"}

# --- Stage 3: Algorithm Validation ---
# Prerequisite steps for test-assembly (Personality Assembly Algorithm Validation)
test-query-gen = {shell = "python scripts/maintenance/operation_runner.py test-query-gen pwsh -File ./tests/testing_harness/validate_query_generation.ps1"}
test-assembly-step1 = {shell = "python scripts/maintenance/operation_runner.py test-assembly-step1 python tests/assembly_logic/step_1_generate_coverage_map.py", help = "Step 1: Generate coverage map for assembly logic validation."}
test-assembly-step2 = {shell = "python scripts/maintenance/operation_runner.py test-assembly-step2 python tests/assembly_logic/step_2_select_assembly_logic_subjects.py", help = "Step 2: Select optimal subject set for assembly logic validation."}
test-assembly-step3 = {shell = "python scripts/maintenance/operation_runner.py test-assembly-step3 python tests/assembly_logic/step_3_prepare_assembly_logic_import.py", help = "Step 3: Prepare import file for Solar Fire."}
test-assembly-step4 = {shell = "python scripts/maintenance/operation_runner.py test-assembly-step4 python tests/assembly_logic/step_4_extract_assembly_logic_text.py", help = "Step 5: Extract and assemble the ground truth database."}
test-assembly-step5 = {shell = "python scripts/maintenance/operation_runner.py test-assembly-step5 python tests/assembly_logic/step_5_validate_assembly_logic_subjects.py", help = "Step 6: Validate the assembled ground truth database."}
test-assembly-setup = {shell = "python scripts/maintenance/operation_runner.py test-assembly-setup python tests/assembly_logic/test_assembly_setup.py", help = "Run all steps with interactive pause for manual Solar Fire processing."}
test-assembly = {shell = "python scripts/maintenance/operation_runner.py test-assembly python tests/assembly_logic/run_assembly_validation.py", help = "Validate the personality assembly algorithm against Solar Fire ground truth data."}
test-l3-selection = {shell = "python scripts/maintenance/operation_runner.py test-l3-selection pwsh ./tests/algorithm_validation/validate_selection_algorithms.ps1"}

# --- Stage 4: Unit Tests - Experiment Workflow ---
test-exp-wf = {shell = "python scripts/maintenance/operation_runner.py test-exp-wf pytest tests/experiment_workflow/", help = "Run all experiment workflow unit tests."}

# --- Stage 5: Experiment & Study Integration (Layer 4-5) ---
test-l4 = {shell = "python scripts/maintenance/operation_runner.py test-l4 pwsh -File ./tests/testing_harness/experiment_workflow/layer4/run_layer4_test.ps1"}
test-l4-interactive = {shell = "python scripts/maintenance/operation_runner.py test-l4-interactive pwsh -File ./tests/testing_harness/experiment_workflow/layer4/run_layer4_test.ps1 -Interactive"}
test-l5 = {shell = "python scripts/maintenance/operation_runner.py test-l5 pwsh -File ./tests/testing_harness/experiment_workflow/layer5/run_layer5_test.ps1"}

# --- Stage 6: All Unit Tests Together ---
test = {shell = "python scripts/maintenance/operation_runner.py test python tests/run_all_tests.py {args}", help = "Run all tests (Python and PowerShell) with cleanup."}
cov = {shell = "python scripts/maintenance/operation_runner.py cov pytest --cov=src --cov-report=term-missing", help = "Run all tests with coverage analysis."}
cov-html = {shell = "python scripts/maintenance/operation_runner.py cov-html pytest --cov=src --cov-report=html", help = "Run all tests and generate an HTML coverage report."}
test-cov = {shell = "python scripts/maintenance/operation_runner.py test-cov pytest --cov=src --cov-report= {args}", help = "Run tests for a specific file to update .coverage data."}
report-cov = {shell = "coverage report -m --no-skip-covered {args}", help = "Generate a focused coverage report for specific source file(s)."}

# --- Stage 7: Statistical Validation ---
test-stats-study = {shell = "python scripts/maintenance/operation_runner.py test-stats-study pwsh -File ./tests/algorithm_validation/create_statistical_study.ps1"}
test-stats-imports = {shell = "python scripts/maintenance/operation_runner.py test-stats-imports pwsh -File ./tests/algorithm_validation/generate_graphpad_imports.ps1"}
test-stats-results = {shell = "python scripts/maintenance/operation_runner.py test-stats-results pwsh -File ./tests/algorithm_validation/validate_graphpad_results.ps1"}

# --- PowerShell Wrapper Tests (Used by Integration Tests) ---
test-ps-new-exp = {shell = "python scripts/maintenance/operation_runner.py test-ps-new-exp pwsh ./tests/experiment_workflow/new_experiment.Tests.ps1"}
test-ps-audit-exp = {shell = "python scripts/maintenance/operation_runner.py test-ps-audit-exp pwsh ./tests/experiment_workflow/audit_experiment.Tests.ps1"}
test-ps-fix-exp = {shell = "python scripts/maintenance/operation_runner.py test-ps-fix-exp pwsh ./tests/experiment_workflow/fix_experiment.Tests.ps1"}
test-ps-compile-study = {shell = "python scripts/maintenance/operation_runner.py test-ps-comp-study pwsh ./tests/experiment_workflow/compile_study.Tests.ps1"}
test-ps-audit-study = {shell = "python scripts/maintenance/operation_runner.py test-ps-audit-study pwsh ./tests/experiment_workflow/audit_study.Tests.ps1"}
test-ps-all = {shell = "python scripts/maintenance/operation_runner.py test-ps-all pwsh ./tests/run_all_ps_tests.ps1"}

# --- Composite Test Runners ---
test-ps-exp = {composite = ["test-ps-new-exp", "test-ps-audit-exp", "test-ps-fix-exp"], help = "Run all PowerShell tests for the experiment workflow."}
test-exp-all = {composite = ["test-exp-lc", "test-ps-exp"], help = "Run all Python and PowerShell tests for the experiment workflow."}

[dependency-groups]
dev = [
    "pytest",
    "pre-commit",
    "pypandoc>=1.15",
    "pillow>=10.4.0",
    "pytest-cov>=5.0.0",
    "pytest-mock>=3.15.1",
    "commitizen>=3.31.0",
    "python-docx>=1.2.0",
    "pyfakefs>=5.10.0",
]

[tool.pylance.exclude]
# Add other folders as needed, e.g., "**/node_modules"
exclude = [
    "**/__pycache__",
    "**/.venv",
    "**/output",
    "**/data/backup",
    "**/temp_test_environment",
    "**/_archive",
    "**/htmlcov"
]